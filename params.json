{
  "name": "OscaRobber",
  "tagline": "Analysis of data hosted on IMDB ",
  "body": "## Goal\r\n\r\n> Explore IMDB dataset and user reviews to look behind the scenes of cinematography.\r\n\r\nThis is a synergy project of *Computational Tools for Big Data* and *Social Graphs and Interactions*. We aim at combining knowledge from both courses to make a comprehensive analysis on co-stardom network of movies and actors (and draw some beautiful plots). We will use knowledge on network analysis and perform it highly efficiently using big data concepts learned in the Big Data course.\r\n\r\n## Dataset\r\n\r\n### IMDB\r\n\r\nTo help serve users who want local access to their data, the IMDB offers their data set as plain text files that can be downloaded for free. The IMDb data comes as plain data files having `.list` extension. The files have been downloaded from http://www.imdb.com/interfaces using an FTP client, and include compressed archives created by assembling collections of plain text files of `.list` format. The fetched data includes 52 archives and 4 folders. The size is estimated by 12.63 GB. The files downloaded have a format that is not easily readable by most computational tools learned in the course, therefore the data preparation played a major role in this project, and required a lot of effort. Since files from ftp://ftp.fu-berlin.de/pub/misc/movies/database/ contain somewhat different numbers of columns and rows, and furthermore include different headers, the files had to be translated into a SQL database using a third-party service http://imdbpy.sourceforge.net. But because SQL do not offers infrastructure required to easily access various attributes (and many other downsides, see Explainer Notebook), we have built an infrastructure to transfer the most important data to a NoSQL database. Properties of the resulting database are listed below.\r\n\r\n### User reviews\r\n\r\nFor text analysis we used the *Large Movie Review Dataset v1.0* fetched from http://ai.stanford.edu/~amaas/data/sentiment/. The core dataset contains 50,000 labeled, as well as 50,000 unlabeled documents for unsupervised learning. In the entire collection, no more than 30 reviews are allowed for any given movie because reviews for the same movie tend to have correlated ratings. We used unlabeled data, as we are not interested in already provided sentiments, but want to calculate sentiments on ourselves. User reviews are keyed by IMDB ids rather than primary keys in the SQL database, hence we need to map each IMDB id to the corresponding primary key to be able to compare sentiments with other attributes like gross, release year, and more. As there is no information on IMDB ids in the database itself, we parsed OMDB website to find those.\r\n\r\n### OMDB\r\n\r\nThe OMDb API is a free web service to obtain movie information. We have obtained 60,000 JSON documents using OMDb API. Each JSON document contains following fields.\r\n\r\nWebsite | Fields\r\n--------|-------\r\nIMDB | *Year, Rated, Released, Runtime, Genre, Director, Writer, Actors, Plot, Language, Country, Awards, Poster, imdbRating, imdbVotes, imdbID, Type, DVD, BoxOffice, Production, Website*\r\nRotten Tomatoes | *tomatoMeter, tomatoReviews, tomatoFresh, tomatoRotten, tomatoConsensus, tomatoUserMeter, tomatoUserRating, tomatoUserReviews, tomatoURL*\r\n\r\n### Summary\r\n\r\nThe final collections stored in MongoDB are listed below.\r\n\r\nCollections          |   Count | Size (MB) | Storage (MB)\r\n---------------------|---------|-----------|-------------\r\n`names_map`          | 2851082 |       172 |           80\r\n`prod_countries`     |  951419 |        44 |           18\r\n`release_years`      |  933715 |        46 |           14\r\n`titles_map`         |  933715 |        59 |           28\r\n`genres`             |  886236 |        46 |           22\r\n`directors`          |  853946 |        39 |           19\r\n`languages`          |  848085 |        39 |           13\r\n`cast`               |  725011 |        81 |           62\r\n`prod_companies`     |  634875 |        30 |           14\r\n`runtimes`           |  613963 |        30 |           14\r\n`votes`              |  280444 |        12 |            6\r\n`imdb_ratings`       |  280444 |        13 |            6\r\n`birth_years`        |  278288 |        12 |            6\r\n`keywords`           |  267438 |       138 |          129\r\n`birth_places`       |  250989 |        11 |            4\r\n`prod_companies_map` |  222116 |        14 |            7\r\n`plots`              |  218348 |       148 |          109\r\n`heights`            |  149667 |         7 |            2\r\n`keywords_map`       |  147421 |         9 |            5\r\n`budgets`            |  101221 |         4 |            2\r\n`omdb_files`         |   64176 |        57 |           25\r\n`gross`              |   15568 |         0 |            0\r\n`user_reviews`       |    7091 |        64 |           45\r\n`birth_places_map`   |     385 |         0 |            0\r\n`languages_map`      |     342 |         0 |            0\r\n`prod_countries_map` |     241 |         0 |            0\r\n`genres_map`         |      28 |         0 |            0\r\n\r\n*Hint: Many collections having string values are encoded with integers to save some space, so we introduce collections ending by \"_map\" to get the initial strings values. Don't be scared if you see something like that, it's actually pretty awesome!*\r\n\r\nUsing filtering and intelligent mapping we were able to shrink the total size of IMDB data from 12GB to 1GB. You can download the complete MongoDB database by clicking \"Download\" button above.\r\n\r\n[![Screen Shot 2016-12-05 at 21.18.55.png](https://s14.postimg.org/6tvwwuu8h/Screen_Shot_2016_12_05_at_21_18_55.png)](https://postimg.org/image/jy1h9jma5/)",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}